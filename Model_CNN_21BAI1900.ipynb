{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3QRs-NOhzZLk"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.models as model, torchvision\n","import torchvision.transforms as transforms\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqPVmy5SzpdD"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24431,"status":"ok","timestamp":1710172439993,"user":{"displayName":"Friday V","userId":"05543200725873389140"},"user_tz":-330},"id":"C7xWVKyLztA4","outputId":"14e191ae-8439-4c51-a1a7-e11b2de2cb46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:17<00:00, 9610228.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n"]}],"source":["train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Md0zPnjz-u-"},"outputs":[],"source":["class LeNet(nn.Module):\n","    def __init__(self):\n","        self.\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16*5*5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = torch.nn.functional.relu(self.conv1(x))\n","        x = torch.nn.functional.max_pool2d(x, (2, 2))\n","        x = torch.nn.functional.relu(self.conv2(x))\n","        x = torch.nn.functional.max_pool2d(x, (2, 2))\n","        x = x.view(-1, self.num_flat_features(x))\n","        x = torch.nn.functional.relu(self.fc1(x))\n","        x = torch.nn.functional.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNTnUdVfzzQv"},"outputs":[],"source":["net = LeNet()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kX4ZkJHz10i"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327134,"status":"ok","timestamp":1710172780865,"user":{"displayName":"Friday V","userId":"05543200725873389140"},"user_tz":-330},"id":"IxbxGxnJ1roC","outputId":"8e00a186-0d9a-47f3-89fe-fbb34f65a6cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1,  2000] loss: 2.235\n","[1,  4000] loss: 1.834\n","[1,  6000] loss: 1.661\n","[1,  8000] loss: 1.578\n","[1, 10000] loss: 1.499\n","[1, 12000] loss: 1.473\n","[2,  2000] loss: 1.375\n","[2,  4000] loss: 1.363\n","[2,  6000] loss: 1.338\n","[2,  8000] loss: 1.309\n","[2, 10000] loss: 1.313\n","[2, 12000] loss: 1.284\n","[3,  2000] loss: 1.207\n","[3,  4000] loss: 1.215\n","[3,  6000] loss: 1.189\n","[3,  8000] loss: 1.198\n","[3, 10000] loss: 1.198\n","[3, 12000] loss: 1.171\n","[4,  2000] loss: 1.086\n","[4,  4000] loss: 1.109\n","[4,  6000] loss: 1.093\n","[4,  8000] loss: 1.109\n","[4, 10000] loss: 1.103\n","[4, 12000] loss: 1.112\n","[5,  2000] loss: 1.022\n","[5,  4000] loss: 1.030\n","[5,  6000] loss: 1.044\n","[5,  8000] loss: 1.031\n","[5, 10000] loss: 1.043\n","[5, 12000] loss: 1.038\n"]}],"source":["num_epochs = 5\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        net.train()\n","        inputs, labels = data\n","\n","        optimizer.zero_grad()\n","\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q2S_lIlq1snW"},"outputs":[],"source":["torch.save(net.state_dict(), 'lenet.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":686,"status":"ok","timestamp":1710172781546,"user":{"displayName":"Friday V","userId":"05543200725873389140"},"user_tz":-330},"id":"fVHyheuN264A","outputId":"8dcf41e7-f04a-48c2-a5a9-ef9c1c02bbc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}],"source":["test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1710172781547,"user":{"displayName":"Friday V","userId":"05543200725873389140"},"user_tz":-330},"id":"zR12c0Vr3EvD","outputId":"52eac663-e39e-426f-eee4-442ef83522b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":12}],"source":["net = LeNet()\n","\n","net.load_state_dict(torch.load('lenet.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAtBT-dR3NjX"},"outputs":[],"source":["def test_network(net, test_loader):\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in test_loader:\n","            images, labels = data\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7670,"status":"ok","timestamp":1710172789211,"user":{"displayName":"Friday V","userId":"05543200725873389140"},"user_tz":-330},"id":"caSzd3dV3PLn","outputId":"dc85f1b4-0a41-47f7-faab-49ac2de0b48e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 59 %\n"]}],"source":["test_network(net, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"elapsed":64,"status":"error","timestamp":1710172789212,"user":{"displayName":"Friday V","userId":"05543200725873389140"},"user_tz":-330},"id":"wEDDtw0j3Q3u","outputId":"a7123d62-8158-4470-e0cc-6087ab4469c3"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/download.jpg'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-c5f45114bfb0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/download.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Test the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/download.jpg'"]}],"source":["image = Image.open('/content/download.jpg')\n","image = transform(image).unsqueeze(0)\n","\n","# Test the image\n","output = net(image)\n","_, predicted = torch.max(output, 1)\n","print('Predicted class:', predicted.item())"]},{"cell_type":"markdown","metadata":{"id":"WWp2hB0q54-D"},"source":["#Part 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Df7iNvwt577q"},"outputs":[],"source":["class AlexNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","        )\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hORGAXsvPQHm"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FeWy-HyZQyZd"},"outputs":[],"source":["train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JH9Sf4S1P3pt"},"outputs":[],"source":["net = AlexNet()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VypGFJW3P_Jh"},"outputs":[],"source":["num_epochs = 1\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, labels = data\n","\n","        optimizer.zero_grad()\n","\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        # print('1')\n","        optimizer.step()\n","\n","        # print('2')\n","        running_loss += loss.item()\n","        if i % 30 == 29:\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","        # print('3')\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOgox/ba7W+3I8LDGB+DDqg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}