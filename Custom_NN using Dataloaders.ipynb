{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNh8tOVALNDuthWBChj5vEW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":78,"metadata":{"id":"tyUz8vZ3lT9n","executionInfo":{"status":"ok","timestamp":1710134233410,"user_tz":-330,"elapsed":538,"user":{"displayName":"Friday V","userId":"05543200725873389140"}}},"outputs":[],"source":["import numpy as np, torch as t, torch.nn as nn , torch.nn.functional as F\n","from torchvision import datasets, models\n","import torch.optim as optim\n","import pandas as pd\n","from torchvision.transforms import v2 as T\n","from torch.utils.data import Dataset, DataLoader, TensorDataset"]},{"cell_type":"code","source":["class dataset_load():\n","  def __init__(self,location):\n","    self.loc = location\n","  def load_and_process(self):\n","    df1 = pd.read_csv(\"/content/MBA_ADMISSIONS.csv\")\n","    target = df1.iloc[:,-1]\n","    df1 = df1.iloc[:, :7]\n","    df1['Target'] = target\n","    # d1=dict(enumerate(list(train.department.unique())))\n","    # d_swap = {v: k for k, v in d1.items()}\n","    # train['department'].replace(d_swap, inplace=True)\n","    df1['Target'] = df1['Target'].map({'Marketing':1, 'LOS':0, 'Finance':2, 'HR':3})\n","    df1.sample(7)\n","    return df1\n","\n","d = dataset_load('/content/MBA_ADMISSIONS.csv')\n","df1 = d.load_and_process()"],"metadata":{"id":"E2_iEN1p66XP","executionInfo":{"status":"ok","timestamp":1710134233951,"user_tz":-330,"elapsed":35,"user":{"displayName":"Friday V","userId":"05543200725873389140"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["df1.sample(7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"YGnfS2lv4Nus","executionInfo":{"status":"ok","timestamp":1710134233952,"user_tz":-330,"elapsed":35,"user":{"displayName":"Friday V","userId":"05543200725873389140"}},"outputId":"39c5d0e6-4ad2-4fbe-f007-a94a74dc2e1f"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     pre_score  Age_in_years  Percentage_in_10_Class  Percentage_in_12_Class  \\\n","221  40.000000            23                    93.4                   96.00   \n","333  75.000000            20                    88.0                   79.00   \n","424  60.000000            23                    90.0                   92.00   \n","398  44.000000            21                    97.2                   91.00   \n","205  66.666667            22                    82.0                   78.83   \n","202  42.000000            21                    89.4                   95.60   \n","420  60.000000            20                    93.0                   92.00   \n","\n","     Percentage_in_Under_Graduate  percentage_MBA  post_score  Target  \n","221                          83.4           67.00   90.000000       2  \n","333                          69.0           57.00   55.000000       1  \n","424                          79.0           72.54   75.000000       0  \n","398                          68.0           62.00   66.666667       0  \n","205                          65.0           69.30   63.333333       1  \n","202                          77.0           65.11   86.666667       1  \n","420                          77.0           69.00   85.000000       0  "],"text/html":["\n","  <div id=\"df-90bccc26-beb3-4fd0-9d31-d18411180c02\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pre_score</th>\n","      <th>Age_in_years</th>\n","      <th>Percentage_in_10_Class</th>\n","      <th>Percentage_in_12_Class</th>\n","      <th>Percentage_in_Under_Graduate</th>\n","      <th>percentage_MBA</th>\n","      <th>post_score</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>221</th>\n","      <td>40.000000</td>\n","      <td>23</td>\n","      <td>93.4</td>\n","      <td>96.00</td>\n","      <td>83.4</td>\n","      <td>67.00</td>\n","      <td>90.000000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>333</th>\n","      <td>75.000000</td>\n","      <td>20</td>\n","      <td>88.0</td>\n","      <td>79.00</td>\n","      <td>69.0</td>\n","      <td>57.00</td>\n","      <td>55.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>424</th>\n","      <td>60.000000</td>\n","      <td>23</td>\n","      <td>90.0</td>\n","      <td>92.00</td>\n","      <td>79.0</td>\n","      <td>72.54</td>\n","      <td>75.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>398</th>\n","      <td>44.000000</td>\n","      <td>21</td>\n","      <td>97.2</td>\n","      <td>91.00</td>\n","      <td>68.0</td>\n","      <td>62.00</td>\n","      <td>66.666667</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>205</th>\n","      <td>66.666667</td>\n","      <td>22</td>\n","      <td>82.0</td>\n","      <td>78.83</td>\n","      <td>65.0</td>\n","      <td>69.30</td>\n","      <td>63.333333</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>202</th>\n","      <td>42.000000</td>\n","      <td>21</td>\n","      <td>89.4</td>\n","      <td>95.60</td>\n","      <td>77.0</td>\n","      <td>65.11</td>\n","      <td>86.666667</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>60.000000</td>\n","      <td>20</td>\n","      <td>93.0</td>\n","      <td>92.00</td>\n","      <td>77.0</td>\n","      <td>69.00</td>\n","      <td>85.000000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90bccc26-beb3-4fd0-9d31-d18411180c02')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-90bccc26-beb3-4fd0-9d31-d18411180c02 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-90bccc26-beb3-4fd0-9d31-d18411180c02');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3cb7e91d-d4c1-4644-9594-cb4c3831beed\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cb7e91d-d4c1-4644-9594-cb4c3831beed')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3cb7e91d-d4c1-4644-9594-cb4c3831beed button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df1\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"pre_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.540650145460004,\n        \"min\": 40.0,\n        \"max\": 75.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          40.0,\n          75.0,\n          42.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age_in_years\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 20,\n        \"max\": 23,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          20,\n          22,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percentage_in_10_Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.8213809521457955,\n        \"min\": 82.0,\n        \"max\": 97.2,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          93.4,\n          88.0,\n          89.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percentage_in_12_Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.276638090819269,\n        \"min\": 78.83,\n        \"max\": 96.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          96.0,\n          79.0,\n          95.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percentage_in_Under_Graduate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.749532611684344,\n        \"min\": 65.0,\n        \"max\": 83.4,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          83.4,\n          69.0,\n          77.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percentage_MBA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.187377996270417,\n        \"min\": 57.0,\n        \"max\": 72.54,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          67.0,\n          57.0,\n          65.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.323409005597002,\n        \"min\": 55.0,\n        \"max\": 90.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          90.0,\n          55.0,\n          86.66666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["class classify(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.l1 = nn.Linear(7,14)\n","    self.l2 = nn.Linear(14,8)\n","    self.l3 = nn.Linear(8,4)\n","    self.softmax = nn.Softmax(dim=1)\n","  def forward(self,x):\n","    x = F.relu(self.l1(x))\n","    x = F.relu(self.l2(x))\n","    x = self.softmax(self.l3(x))\n","    return x\n","\n","model = classify()"],"metadata":{"id":"c1k9QOOl6V22","executionInfo":{"status":"ok","timestamp":1710134233953,"user_tz":-330,"elapsed":32,"user":{"displayName":"Friday V","userId":"05543200725873389140"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["loss_fxn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(),lr=0.01)"],"metadata":{"id":"oVY5KP9ssBzx","executionInfo":{"status":"ok","timestamp":1710134233954,"user_tz":-330,"elapsed":32,"user":{"displayName":"Friday V","userId":"05543200725873389140"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["#calculating mean and sd for all columns.\n","\n","ml =[]\n","sdl = []\n","\n","for i in df1.columns:\n","  ml.append(np.mean(df1[i]))\n","  sdl.append(np.std(df1[i]))\n","  print(f'Mean of {i[:13]} is --{ml[-1]}-- and sd is --{sdl[-1]}--',end='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHaDQfB9sa7E","executionInfo":{"status":"ok","timestamp":1710134233955,"user_tz":-330,"elapsed":32,"user":{"displayName":"Friday V","userId":"05543200725873389140"}},"outputId":"beb2b538-e851-43a1-948a-a6f4bed0338b"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean of pre_score is --68.1818181822833-- and sd is --13.829843440630812--\n","Mean of Age_in_years is --22.560253699788582-- and sd is --1.7059358932236102--\n","Mean of Percentage_in is --84.01854122621563-- and sd is --8.217045231277908--\n","Mean of Percentage_in is --81.55610993657504-- and sd is --9.762943686921622--\n","Mean of Percentage_in is --73.40513742071883-- and sd is --7.642432419706675--\n","Mean of percentage_MB is --67.87416490486258-- and sd is --3.756761696778134--\n","Mean of post_score is --76.21564482046513-- and sd is --13.501999069432133--\n","Mean of Target is --1.285412262156448-- and sd is --0.9224351270713493--\n"]}]},{"cell_type":"code","source":["data_transformers = {\n","    'train': T.Compose([\n","        T.ToTensor(),\n","        T.ToDtype(t.float32, scale=True)\n","    ]),\n","    'val' : T.Compose([\n","        T.ToTensor(),\n","        T.ToDtype(t.float32, scale=True)\n","    ])\n","    }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2YADTHgn8e6","executionInfo":{"status":"ok","timestamp":1710134233956,"user_tz":-330,"elapsed":29,"user":{"displayName":"Friday V","userId":"05543200725873389140"}},"outputId":"cdbd5f33-8946-4a4f-e7a7-e6a7839e67dc"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from torch.utils.data import SubsetRandomSampler\n","\n","#To Tensors\n","features = t.tensor(df1.iloc[:, :-1].values, dtype=t.float32)\n","targets = t.tensor(df1.iloc[:, -1].values, dtype=t.long)\n","\n","# Create TensorDataset\n","dataset = TensorDataset(features, targets)\n","\n","#Create ratio parttiiton\n","train_size = int(0.7 * len(df1))\n","test_size = len(df1) - train_size\n","train_sampler = SubsetRandomSampler(range(train_size))\n","test_sampler = SubsetRandomSampler(range(train_size, len(df1)))\n","\n","# Create DataLoader\n","batch_size = 32\n","train_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n","test_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n","\n","# Print data from DataLoader\n","for batch_idx, (features, target) in enumerate(train_dataloader):\n","    print(f\"Batch {batch_idx} - Features: {features}, Target: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AG_zNgGd3MmI","executionInfo":{"status":"ok","timestamp":1710134234402,"user_tz":-330,"elapsed":470,"user":{"displayName":"Friday V","userId":"05543200725873389140"}},"outputId":"2423ccd3-c8bf-4de1-8f40-ab1987874f8e"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 - Features: tensor([[ 81.6667,  21.0000,  84.0000,  85.0000,  83.0000,  66.6000,  93.3333],\n","        [ 61.6667,  26.0000,  88.0000,  84.0000,  74.0000,  66.0000,  66.6667],\n","        [ 88.3333,  23.0000,  77.0000,  87.0000,  65.0000,  65.0000,  35.0000],\n","        [ 40.0000,  22.0000,  85.0000,  89.0000,  63.0000,  70.0000,  78.3333],\n","        [ 43.0000,  22.0000,  78.0000,  80.0000,  87.0000,  67.2700, 100.0000],\n","        [ 76.6667,  24.0000,  89.4000,  90.7500,  76.7000,  77.4100,  85.0000],\n","        [ 78.3333,  23.0000,  95.0000,  93.0000,  83.0000,  71.5000,  83.3333],\n","        [100.0000,  22.0000,  78.0000,  80.0000,  87.0000,  67.2700, 100.0000],\n","        [ 93.3333,  22.0000,  92.0000,  94.0000,  78.7100,  66.2900,  73.3333],\n","        [ 71.6667,  20.0000,  79.0000,  81.0000,  76.0000,  63.0000, 100.0000],\n","        [ 76.6667,  26.0000,  93.2000,  83.8000,  77.0000,  74.9700,  75.0000],\n","        [ 60.0000,  23.0000,  90.0000,  92.0000,  79.0000,  72.5400,  75.0000],\n","        [ 75.0000,  22.0000,  69.6000,  65.2500,  62.0000,  62.0000,  86.6667],\n","        [ 55.0000,  22.0000,  93.1000,  88.4000,  80.0100,  69.1700,  55.0000],\n","        [ 60.0000,  20.0000,  93.0000,  92.0000,  77.0000,  69.0000,  85.0000],\n","        [ 52.0000,  23.0000,  94.4000,  92.7500,  74.4000,  72.6000,  75.0000],\n","        [ 83.3333,  21.0000,  74.1000,  86.8000,  70.6300,  68.5000,  80.0000],\n","        [ 68.3333,  24.0000,  90.0000,  96.0000,  75.0000,  72.4400,  76.6667],\n","        [ 76.6667,  23.0000,  88.6000,  76.4000,  74.6000,  71.4300,  88.3333],\n","        [ 90.0000,  25.0000,  83.0000,  64.0000,  77.0000,  71.2500,  86.6667],\n","        [ 81.6667,  21.0000,  85.0000,  81.0000,  78.0000,  66.5400,  86.6667],\n","        [ 86.6667,  24.0000,  68.0000,  63.0000,  64.0000,  60.0000,  80.0000],\n","        [ 42.0000,  22.0000,  95.5200,  92.6700,  79.5000,  73.3000,  86.6667],\n","        [ 83.3333,  20.0000,  93.2000,  94.7500,  74.0000,  65.6000,  73.3333],\n","        [ 81.6667,  20.0000,  70.3000,  88.0000,  65.0000,  64.3800,  95.0000],\n","        [ 44.0000,  21.0000,  97.2000,  91.0000,  68.0000,  62.0000,  66.6667],\n","        [ 61.6667,  20.0000,  93.0000,  94.8000,  84.5500,  69.4000,  58.3333],\n","        [ 66.6667,  22.0000,  82.0000,  78.8300,  65.0000,  69.3000,  63.3333],\n","        [ 90.0000,  23.0000,  79.0000,  90.0000,  71.0000,  66.0000,  91.6667],\n","        [ 63.3333,  23.0000,  75.0000,  72.0000,  70.0000,  67.0000,  80.0000],\n","        [ 61.6667,  25.0000,  83.6000,  80.6000,  62.0000,  73.5500,  66.6667],\n","        [ 75.0000,  20.0000,  58.9000,  76.0000,  68.5700,  63.7700,  75.0000]]), Target: tensor([3, 1, 1, 2, 2, 0, 2, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 3, 1, 1, 2, 2, 2,\n","        1, 0, 2, 1, 2, 1, 0, 1])\n","Batch 1 - Features: tensor([[ 83.3333,  23.0000,  67.0000,  62.0000,  67.0000,  63.0000,  80.0000],\n","        [ 55.0000,  23.0000,  89.3000,  79.2000,  72.5600,  70.3200,  78.3333],\n","        [ 63.3333,  24.0000,  87.0000,  83.0000,  63.0000,  72.7000,  68.3333],\n","        [ 43.0000,  23.0000,  79.0000,  70.0000,  81.6000,  64.0000,   7.0000],\n","        [ 70.0000,  26.0000,  89.1200,  84.0000,  69.3400,  68.3800,  71.6667],\n","        [ 71.6667,  24.0000,  79.8000,  61.6000,  60.3300,  69.2800,  76.6667],\n","        [ 63.3333,  22.0000,  72.0000,  83.0000,  69.0000,  63.0000,  73.3333],\n","        [ 51.6667,  22.0000,  91.2000,  94.4000,  73.1500,  70.6700,  71.6667],\n","        [ 71.6667,  25.0000,  77.6000,  82.6000,  76.9000,  66.8500,  76.6667],\n","        [ 76.6667,  24.0000,  86.0000,  69.0000,  73.0000,  68.0000,   8.0000],\n","        [ 81.6667,  25.0000,  86.0000,  75.0000,  65.0000,  66.4000,  81.6667],\n","        [ 71.6667,  23.0000,  89.3300,  84.6000,  66.4000,  63.0800, 100.0000],\n","        [ 80.0000,  25.0000,  77.8000,  62.2000,  60.1000,  68.4800,  73.3333],\n","        [ 88.3333,  23.0000,  84.0000,  74.0000,  66.0000,  63.2600,  90.0000],\n","        [ 83.3333,  21.0000,  74.1000,  86.8000,  70.6300,  68.5000,  80.0000],\n","        [ 46.0000,  24.0000,  72.0000,  85.0000,  72.0000,  66.0900,  95.0000],\n","        [ 61.6667,  20.0000,  70.0000,  83.0000,  63.0000,  62.0000,  66.6667],\n","        [ 75.0000,  22.0000,  81.0000,  84.5000,  86.0000,  64.0000,  81.6667],\n","        [ 55.0000,  21.0000,  76.0000,  75.2000,  61.0000,  65.0000,  71.6667],\n","        [ 51.6667,  22.0000,  91.2000,  94.4000,  73.1500,  70.6700,  71.6667],\n","        [ 80.0000,  25.0000,  77.8000,  62.2000,  60.1000,  68.4800,  73.3333],\n","        [ 93.3333,  22.0000,  92.0000,  94.0000,  78.7100,  66.2900,  73.3333],\n","        [ 73.3333,  20.0000,  75.3600,  83.5000,  84.5000,  66.0000,  80.0000],\n","        [ 40.0000,  21.0000,  93.3000,  91.5000,  72.5000,  65.0000,  75.0000],\n","        [ 61.6667,  25.0000,  83.6000,  80.6000,  62.0000,  73.5500,  66.6667],\n","        [ 75.0000,  22.0000,  71.0000,  74.8000,  72.0000,  61.0000,  83.3333],\n","        [ 76.6667,  23.0000,  94.4000,  92.7500,  74.0000,  72.6000,  75.0000],\n","        [ 68.3333,  20.0000,  80.0000,  81.2000,  76.0000,  69.6500,  76.6667],\n","        [ 50.0000,  22.0000,  87.5000,  72.4000,  64.0000,  66.0000,  51.6667],\n","        [ 71.6667,  22.0000,  95.0000,  78.6000,  75.4300,  68.5400,  88.3333],\n","        [ 53.3333,  21.0000,  70.4000,  80.3000,  60.1500,  65.8400,  70.0000],\n","        [ 50.0000,  22.0000,  87.5000,  72.4000,  64.0000,  66.0000,  51.6667]]), Target: tensor([1, 0, 2, 2, 0, 2, 2, 0, 0, 2, 1, 2, 0, 1, 2, 2, 2, 1, 2, 0, 0, 0, 2, 0,\n","        0, 1, 1, 3, 3, 1, 1, 3])\n","Batch 2 - Features: tensor([[ 65.0000,  21.0000,  87.4000,  91.2000,  69.8000,  67.4600,  68.3333],\n","        [ 70.0000,  21.0000,  91.2000,  90.2000,  86.0000,  74.2250,  68.3333],\n","        [ 86.6667,  22.0000,  89.9000,  83.4000,  84.1000,  73.9100,  83.3333],\n","        [ 86.6667,  26.0000,  84.0000,  91.5000,  71.4400,  68.0000,  73.3333],\n","        [ 75.0000,  22.0000,  68.0000,  88.0000,  76.0000,  65.0000,  75.0000],\n","        [ 33.3333,  21.0000,  91.0000,  93.0000,  89.5000,  75.6000,  63.3333],\n","        [ 68.3333,  20.0000,  80.0000,  81.2000,  76.0000,  69.6500,  76.6667],\n","        [ 66.6667,  21.0000,  81.2800,  89.3300,  78.0000,  63.2000,  70.0000],\n","        [ 86.6667,  23.0000,  79.0000,  90.0000,  71.0000,  66.0000,  91.6667],\n","        [ 68.3333,  22.0000,  90.0000,  88.8000,  67.0000,  69.8400,  73.3333],\n","        [ 65.0000,  22.0000,  88.1600,  79.8000,  78.8000,  67.0000,  91.6667],\n","        [ 71.6667,  23.0000,  89.3300,  84.6000,  66.4000,  63.0800, 100.0000],\n","        [ 90.0000,  25.0000,  83.0000,  64.0000,  77.0000,  71.2500,  86.6667],\n","        [ 73.3333,  23.0000,  80.6700,  60.2900,  70.5800,  62.0600,  93.3333],\n","        [ 88.3333,  23.0000,  84.0000,  74.0000,  66.0000,  63.2600,  90.0000],\n","        [ 90.0000,  22.0000,  78.0000,  80.0000,  87.0000,  67.2700, 100.0000],\n","        [ 60.0000,  23.0000,  88.6700,  85.2900,  75.5000,  68.1000,  80.0000],\n","        [ 81.6667,  21.0000,  85.0000,  81.0000,  78.0000,  66.5400,  86.6667],\n","        [ 85.0000,  26.0000,  86.4000,  80.4000,  70.2200,  70.4800,  76.6667],\n","        [ 81.6667,  21.0000,  84.0000,  85.0000,  83.0000,  66.6000,  93.3333],\n","        [ 60.0000,  20.0000,  88.0000,  87.8000,  65.0000,  70.2500,  81.6667],\n","        [ 75.0000,  22.0000,  71.0000,  74.8000,  72.0000,  61.0000,  83.3333],\n","        [ 75.0000,  21.0000,  89.4000,  70.0000,  81.5800,  72.0000,  70.0000],\n","        [ 68.3333,  22.0000,  91.2500,  92.0000,  75.5000,  63.5000,  56.6667],\n","        [ 30.0000,  21.0000,  79.8000,  65.5000,  81.7500,  68.8800,  48.3333],\n","        [ 73.3333,  22.0000,  76.0000,  79.0000,  68.0000,  63.8000,  95.0000],\n","        [ 68.3333,  22.0000,  89.3000,  89.0000,  70.5300,  71.9400,  75.0000],\n","        [ 46.0000,  24.0000,  82.3000,  65.5000,  69.0000,  66.0000,  66.6667],\n","        [ 68.3333,  22.0000,  91.2500,  92.0000,  75.5000,  63.5000,  56.6667],\n","        [ 76.6667,  21.0000,  95.0000,  67.0000,  70.0000,  66.2200,  86.6667],\n","        [ 75.0000,  20.0000,  58.9000,  76.0000,  68.5700,  63.7700,  75.0000],\n","        [ 55.0000,  24.0000,  75.8000,  75.6000,  63.8600,  64.9500,  63.3333]]), Target: tensor([3, 2, 3, 1, 1, 2, 3, 2, 2, 0, 1, 2, 1, 3, 1, 2, 1, 1, 0, 3, 1, 1, 2, 1,\n","        2, 1, 2, 1, 1, 3, 1, 0])\n","Batch 3 - Features: tensor([[ 60.0000,  25.0000,  85.0000,  79.0000,  68.0000,  65.0000,  61.6667],\n","        [ 60.0000,  20.0000,  93.0000,  92.0000,  77.0000,  69.0000,  85.0000],\n","        [ 76.6667,  23.0000,  88.6000,  76.4000,  74.6000,  71.4300,  88.3333],\n","        [ 63.3333,  23.0000,  95.0000,  85.0000,  85.0000,  70.6400,  78.3333],\n","        [ 78.3333,  25.0000,  71.6700,  89.9800,  73.0000,  67.1900,  88.3333],\n","        [ 40.0000,  23.0000,  93.4000,  96.0000,  83.4000,  67.0000,  90.0000],\n","        [ 86.6667,  26.0000,  84.0000,  91.5000,  71.4400,  68.0000,  73.3333],\n","        [ 66.6667,  21.0000,  81.2800,  89.3300,  78.0000,  63.2000,  70.0000],\n","        [ 42.0000,  21.0000,  89.4000,  95.6000,  77.0000,  65.1100,  86.6667],\n","        [ 76.6667,  23.0000,  88.6000,  76.4000,  74.6000,  71.4300,  88.3333],\n","        [ 63.3333,  21.0000,  84.6600,  79.6600,  70.0000,  67.0800,  88.3333],\n","        [ 73.3333,  20.0000,  75.3600,  83.5000,  84.5000,  66.0000,  80.0000],\n","        [ 90.0000,  25.0000,  79.4000,  64.0000,  71.2000,  66.8000,  85.0000],\n","        [ 75.0000,  22.0000,  81.0000,  84.5000,  86.0000,  64.0000,  81.6667],\n","        [ 40.0000,  22.0000,  85.0000,  89.0000,  63.0000,  70.0000,  78.3333],\n","        [ 68.3333,  22.0000,  91.2000,  78.0000,  69.8000,  70.5100,  73.3333],\n","        [ 50.0000,  22.0000,  87.5000,  72.4000,  64.0000,  66.0000,  51.6667],\n","        [ 76.6667,  25.0000,  77.8000,  62.2000,  60.1000,  68.4800,  73.3333],\n","        [ 75.0000,  21.0000,  89.4000,  70.0000,  81.5800,  72.0000,  70.0000],\n","        [ 40.0000,  23.0000,  93.4000,  96.0000,  83.4000,  67.0000,  90.0000],\n","        [ 73.3333,  22.0000,  82.0000,  70.0000,  76.5000,  67.0000,  81.6667],\n","        [ 55.0000,  23.0000,  89.3000,  79.2000,  72.5600,  70.3200,  78.3333],\n","        [ 76.6667,  25.0000,  88.8000,  90.0000,  78.6000,  70.6400,  85.0000],\n","        [ 75.0000,  21.0000,  89.4000,  70.0000,  81.5800,  72.0000,  70.0000],\n","        [ 46.6667,  20.0000,  80.0000,  93.2500,  75.0000,  63.3000,  78.3333],\n","        [ 85.0000,  24.0000,  81.8000,  85.1600,  63.5000,  68.0000,  78.3333],\n","        [ 50.0000,  20.0000,  72.0000,  66.0000,  60.0000,  60.7000,  71.6667],\n","        [ 75.0000,  21.0000,  85.0000,  88.0000,  79.0000,  70.6000,  75.0000],\n","        [ 46.6667,  20.0000,  80.0000,  93.2500,  75.0000,  63.3000,  78.3333],\n","        [ 66.6667,  22.0000,  82.0000,  78.8300,  65.0000,  69.3000,  63.3333],\n","        [ 91.6667,  20.0000,  94.4000,  97.1700,  94.0000,  73.4100,  88.3333],\n","        [ 71.6667,  23.0000,  89.3300,  84.6000,  66.4000,  63.0800, 100.0000]]), Target: tensor([0, 0, 3, 1, 2, 2, 1, 2, 1, 3, 1, 2, 0, 1, 2, 1, 3, 0, 2, 2, 1, 0, 0, 2,\n","        1, 0, 1, 3, 1, 1, 2, 2])\n","Batch 4 - Features: tensor([[ 63.3333,  23.0000,  75.0000,  72.0000,  70.0000,  67.0000,  80.0000],\n","        [ 60.0000,  20.0000,  88.0000,  87.8000,  65.0000,  70.2500,  81.6667],\n","        [ 73.3333,  25.0000,  96.3200,  93.8300,  90.4000,  76.8300,  76.6667],\n","        [ 90.0000,  25.0000,  83.0000,  64.0000,  77.0000,  71.2500,  86.6667],\n","        [ 76.6667,  23.0000,  94.4000,  92.7500,  74.0000,  72.6000,  75.0000],\n","        [ 70.0000,  24.0000,  82.2000,  71.4000,  64.2500,  70.1900,  76.6667],\n","        [ 73.3333,  22.0000,  82.0000,  70.0000,  76.5000,  67.0000,  81.6667],\n","        [ 46.0000,  23.0000,  85.8000,  84.6000,  89.0000,  69.4000, 100.0000],\n","        [ 60.0000,  21.0000,  89.4000,  95.6000,  77.0000,  65.1100,  86.6667],\n","        [ 76.6667,  23.0000,  88.6000,  76.4000,  74.6000,  71.4300,  88.3333],\n","        [ 63.3333,  25.0000,  87.0000,  84.2000,  78.1300,  69.2200,  78.3333],\n","        [ 60.0000,  20.0000,  93.0000,  85.0000,  66.0000,  65.0000,  86.6667],\n","        [ 43.0000,  23.0000,  79.0000,  70.0000,  81.6000,  64.0000,   7.0000],\n","        [ 61.6667,  24.0000,  83.3000,  77.0000,  67.1000,  67.2700,  66.6667],\n","        [ 75.0000,  21.0000,  89.4000,  70.0000,  81.5800,  72.0000,  70.0000],\n","        [ 71.6667,  25.0000,  87.0000,  94.8000,  78.0000,  73.0000,  73.3333],\n","        [ 40.0000,  21.0000,  68.0000,  88.0000,  76.0000,  65.0000,  75.0000],\n","        [ 76.6667,  26.0000,  93.2000,  83.8000,  77.0000,  74.9700,  75.0000],\n","        [ 75.0000,  23.0000,  80.6000,  68.3000,  73.0000,  67.4000,  50.0000],\n","        [ 63.3333,  21.0000,  84.6600,  79.6600,  70.0000,  67.0800,  88.3333],\n","        [ 71.6667,  20.0000,  79.0000,  81.0000,  76.0000,  63.0000, 100.0000],\n","        [ 65.0000,  24.0000,  79.0000,  61.0000,  70.0000,  68.0000,  71.6667],\n","        [ 75.0000,  20.0000,  58.9000,  76.0000,  68.5700,  63.7700,  75.0000],\n","        [ 43.0000,  22.0000,  78.0000,  80.0000,  87.0000,  67.2700, 100.0000],\n","        [ 55.0000,  22.0000,  93.1000,  88.4000,  80.0100,  69.1700,  55.0000],\n","        [ 83.3333,  21.0000,  83.6000,  73.4000,  82.2200,  68.2200,  76.6667],\n","        [ 71.6667,  22.0000,  95.0000,  78.6000,  75.4300,  68.5400,  88.3333],\n","        [ 91.6667,  26.0000,  75.7500,  61.8600,  67.8800,  68.3800,  95.0000],\n","        [ 80.0000,  24.0000,  83.4000,  79.6000,  81.0000,  73.0500,  88.3333],\n","        [ 76.6667,  21.0000,  66.5000,  87.5000,  69.1700,  70.5000,  88.3333],\n","        [ 60.0000,  21.0000,  89.4000,  95.6000,  77.0000,  65.1100,  86.6667],\n","        [ 70.0000,  19.0000,  86.8000,  72.6000,  78.9000,  69.6200,  78.3333]]), Target: tensor([1, 1, 0, 1, 1, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 0, 1, 2, 1, 1, 1, 1, 1, 2,\n","        2, 2, 1, 0, 0, 2, 1, 1])\n","Batch 5 - Features: tensor([[ 81.6667,  23.0000,  87.0000,  89.0000,  80.0000,  67.1400,  83.3333],\n","        [ 60.0000,  22.0000,  74.1000,  78.0000,  65.0000,  61.5900,  58.3333],\n","        [ 36.6667,  22.0000,  96.0000,  80.0000,  65.0000,  64.0000,  60.0000],\n","        [ 86.6667,  24.0000,  68.0000,  63.0000,  64.0000,  60.0000,  80.0000],\n","        [ 40.0000,  22.0000,  85.0000,  89.0000,  63.0000,  70.0000,  78.3333],\n","        [ 46.6667,  21.0000,  84.3300,  88.7000,  74.1900,  71.1100,  83.3333],\n","        [ 61.6667,  26.0000,  88.0000,  84.0000,  74.0000,  66.0000,  66.6667],\n","        [ 76.6667,  26.0000,  93.2000,  83.8000,  77.0000,  74.9700,  75.0000],\n","        [ 55.0000,  21.0000,  76.0000,  75.2000,  61.0000,  65.0000,  71.6667],\n","        [ 66.6667,  22.0000,  91.2000,  80.0000,  67.0000,  68.3000,  60.0000],\n","        [ 86.6667,  24.0000,  68.0000,  63.0000,  64.0000,  60.0000,  80.0000],\n","        [ 50.0000,  22.0000,  87.5000,  72.4000,  64.0000,  66.0000,  51.6667],\n","        [ 55.0000,  23.0000,  89.3000,  79.2000,  72.5600,  70.3200,  78.3333],\n","        [ 60.0000,  25.0000,  85.0000,  79.0000,  68.0000,  65.0000,  61.6667],\n","        [ 71.6667,  25.0000,  77.6000,  82.6000,  76.9000,  66.8500,  76.6667],\n","        [ 54.0000,  20.0000,  94.0000,  97.0000,  94.0000,  73.4100,  88.3333],\n","        [ 76.6667,  26.0000,  93.2000,  83.8000,  77.0000,  74.9700,  75.0000],\n","        [ 80.0000,  25.0000,  77.8000,  62.2000,  60.1000,  68.4800,  73.3333],\n","        [ 70.0000,  24.0000,  82.2000,  71.4000,  64.2500,  70.1900,  76.6667],\n","        [ 63.3333,  22.0000,  72.0000,  83.0000,  69.0000,  63.0000,  73.3333],\n","        [ 91.6667,  23.0000,  86.0000,  85.0000,  85.0000,  69.4000, 100.0000],\n","        [100.0000,  22.0000,  78.0000,  80.0000,  87.0000,  67.2700, 100.0000],\n","        [ 78.3333,  23.0000,  87.4000,  79.8000,  74.9200,  71.8400,  68.3333],\n","        [ 76.6667,  25.0000,  83.4000,  79.0000,  66.8000,  66.1000,  80.0000],\n","        [ 60.0000,  20.0000,  93.0000,  85.0000,  66.0000,  65.0000,  86.6667],\n","        [ 73.3333,  22.0000,  76.0000,  79.0000,  68.0000,  63.8000,  95.0000],\n","        [ 51.6667,  22.0000,  95.0000,  84.8000,  79.0900,  67.7100,  61.6667],\n","        [ 60.0000,  22.0000,  89.8000,  82.5000,  62.3750,  71.0000,  75.0000],\n","        [ 75.0000,  22.0000,  69.6000,  65.2500,  62.0000,  62.0000,  86.6667],\n","        [ 63.3333,  24.0000,  87.0000,  83.0000,  63.0000,  72.7000,  68.3333],\n","        [ 60.0000,  21.0000,  92.4000,  89.0000,  77.0000,  75.0000,  71.6667],\n","        [ 36.6667,  22.0000,  96.0000,  80.0000,  65.0000,  64.0000,  60.0000]]), Target: tensor([3, 2, 1, 2, 2, 3, 1, 2, 2, 2, 2, 3, 0, 0, 0, 2, 2, 0, 2, 2, 3, 2, 1, 1,\n","        3, 1, 2, 2, 1, 2, 2, 1])\n","Batch 6 - Features: tensor([[ 55.0000,  23.0000,  89.3000,  79.2000,  72.5600,  70.3200,  78.3333],\n","        [ 76.6667,  24.0000,  89.4000,  90.7500,  76.7000,  77.4100,  85.0000],\n","        [ 76.6667,  24.0000,  93.4000,  96.5800,  91.7000,  73.1700,  85.0000],\n","        [ 71.6667,  25.0000,  77.6000,  82.6000,  76.9000,  66.8500,  76.6667],\n","        [ 65.0000,  23.0000,  84.0000,  85.0000,  74.0000,  71.3000,  70.0000],\n","        [ 68.3333,  22.0000,  90.0000,  88.8000,  67.0000,  69.8400,  73.3333],\n","        [ 61.6667,  24.0000,  83.3000,  77.0000,  67.1000,  67.2700,  66.6667],\n","        [ 76.6667,  25.0000,  77.8000,  62.2000,  60.1000,  68.4800,  73.3333],\n","        [ 78.3333,  25.0000,  71.6700,  89.9800,  73.0000,  67.1900,  88.3333],\n","        [ 65.0000,  21.0000,  88.8900,  72.4400,  93.0000,  67.6000,  73.3333],\n","        [ 63.3333,  23.0000,  92.0000,  87.5000,  77.7000,  61.0000,  65.0000],\n","        [ 90.0000,  23.0000,  79.0000,  90.0000,  71.0000,  66.0000,  91.6667],\n","        [ 65.0000,  23.0000,  84.0000,  85.0000,  74.0000,  71.3000,  70.0000],\n","        [ 73.3333,  23.0000,  80.6700,  60.2900,  70.5800,  62.0600,  93.3333],\n","        [ 60.0000,  20.0000,  93.0000,  92.0000,  77.0000,  69.0000,  85.0000],\n","        [ 63.3333,  25.0000,  87.0000,  84.2000,  78.1300,  69.2200,  78.3333],\n","        [ 65.0000,  24.0000,  79.0000,  61.0000,  70.0000,  68.0000,  71.6667],\n","        [ 85.0000,  26.0000,  86.4000,  80.4000,  70.2200,  70.4800,  76.6667],\n","        [ 81.6667,  22.0000,  92.8000,  84.8000,  78.0000,  69.8700,  83.3333],\n","        [ 88.3333,  23.0000,  77.0000,  87.0000,  65.0000,  65.0000,  35.0000],\n","        [ 86.6667,  26.0000,  84.0000,  91.5000,  71.4400,  68.0000,  73.3333],\n","        [ 60.0000,  23.0000,  90.0000,  92.0000,  79.0000,  72.5400,  75.0000],\n","        [ 76.6667,  22.0000,  86.0000,  76.0000,  77.0000,  65.9000,  63.3333],\n","        [ 42.0000,  21.0000,  89.4000,  95.6000,  77.0000,  65.1100,  86.6667],\n","        [ 50.0000,  20.0000,  72.0000,  66.0000,  60.0000,  60.7000,  71.6667],\n","        [ 61.6667,  21.0000,  80.0000,  92.0000,  75.0000,  60.0000,  65.0000],\n","        [ 83.3333,  21.0000,  74.1000,  86.8000,  70.6300,  68.5000,  80.0000],\n","        [ 46.0000,  24.0000,  82.3000,  65.5000,  69.0000,  66.0000,  66.6667],\n","        [ 55.0000,  21.0000,  76.0000,  75.2000,  61.0000,  65.0000,  71.6667],\n","        [ 85.0000,  24.0000,  81.8000,  85.1600,  63.5000,  68.0000,  78.3333],\n","        [100.0000,  22.0000,  78.0000,  80.0000,  87.0000,  67.2700, 100.0000],\n","        [ 71.6667,  21.0000,  79.8000,  93.8000,  79.0400,  66.0000,  71.6667]]), Target: tensor([0, 0, 3, 0, 3, 0, 1, 0, 2, 1, 1, 2, 3, 3, 0, 2, 1, 0, 3, 1, 1, 0, 1, 1,\n","        1, 1, 2, 1, 2, 0, 2, 1])\n","Batch 7 - Features: tensor([[71.6667, 24.0000, 79.8000, 61.6000, 60.3300, 69.2800, 76.6667],\n","        [91.6667, 26.0000, 75.7500, 61.8600, 67.8800, 68.3800, 95.0000],\n","        [90.0000, 25.0000, 79.4000, 64.0000, 71.2000, 66.8000, 85.0000],\n","        [85.0000, 26.0000, 86.4000, 80.4000, 70.2200, 70.4800, 76.6667],\n","        [44.0000, 21.0000, 97.2000, 91.0000, 68.0000, 62.0000, 66.6667],\n","        [68.3333, 24.0000, 90.0000, 96.0000, 75.0000, 72.4400, 76.6667],\n","        [30.0000, 21.0000, 79.8000, 65.5000, 81.7500, 68.8800, 48.3333],\n","        [53.3333, 21.0000, 70.4000, 80.3000, 60.1500, 65.8400, 70.0000],\n","        [66.6667, 22.0000, 91.2000, 80.0000, 67.0000, 68.3000, 60.0000],\n","        [91.6667, 26.0000, 75.7500, 61.8600, 67.8800, 68.3800, 95.0000],\n","        [76.6667, 21.0000, 66.5000, 87.5000, 69.1700, 70.5000, 88.3333],\n","        [68.3333, 22.0000, 89.3000, 89.0000, 70.5300, 71.9400, 75.0000],\n","        [68.3333, 24.0000, 80.0000, 72.0000, 64.0000, 60.5700, 68.3333],\n","        [65.0000, 22.0000, 88.1600, 79.8000, 78.8000, 67.0000, 91.6667],\n","        [46.6667, 21.0000, 84.3300, 88.7000, 74.1900, 71.1100, 83.3333],\n","        [65.0000, 21.0000, 87.4000, 91.2000, 69.8000, 67.4600, 68.3333],\n","        [40.0000, 26.0000, 88.1600, 84.3000, 74.2000, 66.0000, 66.6667],\n","        [81.6667, 22.0000, 89.6000, 68.6000, 72.0000, 65.6000, 96.6667],\n","        [60.0000, 22.0000, 89.8000, 82.5000, 62.3750, 71.0000, 75.0000],\n","        [80.0000, 24.0000, 83.4000, 79.6000, 81.0000, 73.0500, 88.3333],\n","        [75.0000, 20.0000, 88.0000, 79.0000, 69.0000, 57.0000, 55.0000],\n","        [60.0000, 21.0000, 92.4000, 89.0000, 77.0000, 75.0000, 71.6667],\n","        [75.0000, 20.0000, 58.9000, 76.0000, 68.5700, 63.7700, 75.0000],\n","        [68.3333, 20.0000, 85.5000, 84.2000, 74.0000, 62.0000, 71.6667],\n","        [81.6667, 23.0000, 87.0000, 89.0000, 80.0000, 67.1400, 83.3333],\n","        [54.0000, 20.0000, 94.0000, 97.0000, 94.0000, 73.4100, 88.3333],\n","        [58.3333, 21.0000, 95.0000, 92.4000, 79.8000, 69.0000, 75.0000],\n","        [73.3333, 25.0000, 84.5000, 95.0000, 75.4400, 75.2300, 80.0000],\n","        [58.3333, 21.0000, 95.0000, 92.4000, 79.8000, 69.0000, 75.0000],\n","        [71.6667, 22.0000, 95.0000, 78.6000, 75.4300, 68.5400, 88.3333],\n","        [70.0000, 19.0000, 86.8000, 72.6000, 78.9000, 69.6200, 78.3333],\n","        [91.6667, 20.0000, 94.4000, 97.1700, 94.0000, 73.4100, 88.3333]]), Target: tensor([2, 0, 0, 0, 0, 0, 2, 1, 2, 0, 2, 2, 1, 1, 3, 3, 1, 1, 2, 0, 1, 2, 1, 1,\n","        3, 2, 2, 0, 2, 1, 1, 2])\n","Batch 8 - Features: tensor([[ 40.0000,  22.0000,  85.0000,  89.0000,  63.0000,  70.0000,  78.3333],\n","        [ 40.0000,  21.0000,  93.3000,  91.5000,  72.5000,  65.0000,  75.0000],\n","        [ 90.0000,  25.0000,  83.0000,  64.0000,  77.0000,  71.2500,  86.6667],\n","        [ 65.0000,  22.0000,  83.8500,  86.2000,  87.4500,  71.2200,  56.6667],\n","        [ 70.0000,  26.0000,  89.1200,  84.0000,  69.3400,  68.3800,  71.6667],\n","        [ 40.0000,  26.0000,  88.1600,  84.3000,  74.2000,  66.0000,  66.6667],\n","        [ 40.0000,  21.0000,  68.0000,  88.0000,  76.0000,  65.0000,  75.0000],\n","        [ 81.6667,  21.0000,  70.0000,  67.0000,  65.0000,  59.1600,  95.0000],\n","        [ 68.3333,  22.0000,  89.3000,  89.0000,  70.5300,  71.9400,  75.0000],\n","        [ 55.0000,  23.0000,  89.3000,  79.2000,  72.5600,  70.3200,  78.3333],\n","        [ 75.0000,  22.0000,  68.0000,  88.0000,  76.0000,  65.0000,  75.0000],\n","        [ 73.3333,  25.0000,  96.3200,  93.8300,  90.4000,  76.8300,  76.6667],\n","        [ 68.3333,  20.0000,  85.5000,  84.2000,  74.0000,  62.0000,  71.6667],\n","        [ 61.6667,  24.0000,  83.3000,  77.0000,  67.1000,  67.2700,  66.6667],\n","        [ 60.0000,  22.0000,  74.1000,  78.0000,  65.0000,  61.5900,  58.3333],\n","        [ 65.0000,  21.0000,  88.8900,  72.4400,  93.0000,  67.6000,  73.3333],\n","        [ 76.6667,  25.0000,  83.4000,  79.0000,  66.8000,  66.1000,  80.0000],\n","        [ 91.6667,  23.0000,  86.0000,  85.0000,  85.0000,  69.4000, 100.0000],\n","        [ 73.3333,  22.0000,  82.0000,  70.0000,  76.5000,  67.0000,  81.6667],\n","        [ 65.0000,  24.0000,  79.0000,  61.0000,  70.0000,  68.0000,  71.6667],\n","        [ 61.6667,  20.0000,  93.0000,  94.8000,  84.5500,  69.4000,  58.3333],\n","        [ 76.6667,  23.0000,  91.2000,  90.0000,  75.8000,  67.1900,  35.0000],\n","        [ 90.0000,  25.0000,  83.0000,  64.0000,  77.0000,  71.2500,  86.6667],\n","        [ 78.3333,  23.0000,  95.0000,  93.0000,  83.0000,  71.5000,  83.3333],\n","        [ 73.3333,  25.0000,  84.5000,  95.0000,  75.4400,  75.2300,  80.0000],\n","        [ 86.6667,  22.0000,  89.9000,  83.4000,  84.1000,  73.9100,  83.3333],\n","        [ 83.3333,  23.0000,  67.0000,  62.0000,  67.0000,  63.0000,  80.0000],\n","        [ 60.0000,  23.0000,  88.6700,  85.2900,  75.5000,  68.1000,  80.0000],\n","        [ 60.0000,  20.0000,  93.0000,  92.0000,  77.0000,  69.0000,  85.0000],\n","        [ 76.6667,  22.0000,  95.5200,  92.6600,  79.5000,  73.3000,  86.6667],\n","        [ 46.0000,  24.0000,  72.0000,  85.0000,  72.0000,  66.0900,  95.0000],\n","        [ 81.6667,  22.0000,  89.6000,  68.6000,  72.0000,  65.6000,  96.6667]]), Target: tensor([2, 0, 1, 2, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 2, 1, 1, 3, 1, 1, 2, 0, 1, 2,\n","        0, 3, 1, 1, 0, 2, 2, 1])\n","Batch 9 - Features: tensor([[ 61.6667,  21.0000,  80.0000,  92.0000,  75.0000,  60.0000,  65.0000],\n","        [ 90.0000,  22.0000,  78.0000,  80.0000,  87.0000,  67.2700, 100.0000],\n","        [ 63.3333,  23.0000,  75.0000,  72.0000,  70.0000,  67.0000,  80.0000],\n","        [ 86.6667,  23.0000,  79.0000,  90.0000,  71.0000,  66.0000,  91.6667],\n","        [ 66.6667,  22.0000,  91.2000,  80.0000,  67.0000,  68.3000,  60.0000],\n","        [ 71.6667,  22.0000,  85.5000,  91.1600,  69.0000,  69.6900,  80.0000],\n","        [ 63.3333,  23.0000,  95.0000,  85.0000,  85.0000,  70.6400,  78.3333],\n","        [ 75.0000,  23.0000,  80.6000,  68.3000,  73.0000,  67.4000,  50.0000],\n","        [ 71.6667,  24.0000,  79.8000,  61.6000,  60.3300,  69.2800,  76.6667],\n","        [ 61.6667,  20.0000,  70.0000,  83.0000,  63.0000,  62.0000,  66.6667],\n","        [ 76.6667,  22.0000,  86.0000,  76.0000,  77.0000,  65.9000,  63.3333],\n","        [ 63.3333,  23.0000,  75.0000,  72.0000,  70.0000,  67.0000,  80.0000],\n","        [ 90.0000,  25.0000,  83.0000,  64.0000,  77.0000,  71.2500,  86.6667],\n","        [ 71.6667,  25.0000,  87.0000,  94.8000,  78.0000,  73.0000,  73.3333],\n","        [ 42.0000,  22.0000,  95.5200,  92.6700,  79.5000,  73.3000,  86.6667],\n","        [ 81.6667,  25.0000,  86.0000,  75.0000,  65.0000,  66.4000,  81.6667],\n","        [ 83.3333,  20.0000,  93.2000,  94.7500,  74.0000,  65.6000,  73.3333],\n","        [ 75.0000,  21.0000,  85.0000,  88.0000,  79.0000,  70.6000,  75.0000],\n","        [ 76.6667,  25.0000,  77.8000,  62.2000,  60.1000,  68.4800,  73.3333],\n","        [ 81.6667,  21.0000,  70.0000,  67.0000,  65.0000,  59.1600,  95.0000],\n","        [ 76.6667,  24.0000,  93.4000,  96.5800,  91.7000,  73.1700,  85.0000],\n","        [ 50.0000,  20.0000,  72.0000,  66.0000,  60.0000,  60.7000,  71.6667],\n","        [ 70.0000,  23.0000,  85.0000,  92.0000,  64.0000,  72.0000,  76.6667],\n","        [ 70.0000,  23.0000,  85.0000,  92.0000,  64.0000,  72.0000,  76.6667],\n","        [ 88.3333,  23.0000,  77.0000,  87.0000,  65.0000,  65.0000,  35.0000],\n","        [ 68.3333,  22.0000,  91.2000,  78.0000,  69.8000,  70.5100,  73.3333],\n","        [ 76.6667,  22.0000,  95.5200,  92.6600,  79.5000,  73.3000,  86.6667],\n","        [ 71.6667,  24.0000,  79.8000,  61.6000,  60.3300,  69.2800,  76.6667],\n","        [ 60.0000,  20.0000,  88.0000,  87.8000,  65.0000,  70.2500,  81.6667],\n","        [ 81.6667,  22.0000,  92.8000,  84.8000,  78.0000,  69.8700,  83.3333],\n","        [ 52.0000,  23.0000,  94.4000,  92.7500,  74.4000,  72.6000,  75.0000],\n","        [ 65.0000,  22.0000,  83.8500,  86.2000,  87.4500,  71.2200,  56.6667]]), Target: tensor([1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 3, 0, 0, 3, 1, 2, 2,\n","        1, 1, 2, 2, 1, 3, 1, 2])\n","Batch 10 - Features: tensor([[ 46.0000,  23.0000,  85.8000,  84.6000,  89.0000,  69.4000, 100.0000],\n","        [ 51.6667,  22.0000,  95.0000,  84.8000,  79.0900,  67.7100,  61.6667],\n","        [ 81.6667,  20.0000,  70.3000,  88.0000,  65.0000,  64.3800,  95.0000],\n","        [ 71.6667,  25.0000,  77.6000,  82.6000,  76.9000,  66.8500,  76.6667],\n","        [ 81.6667,  21.0000,  70.0000,  67.0000,  65.0000,  59.1600,  95.0000],\n","        [ 75.0000,  23.0000,  89.7600,  85.6000,  83.0000,  69.3000,  86.6667],\n","        [ 30.0000,  21.0000,  79.8000,  65.5000,  81.7500,  68.8800,  48.3333],\n","        [ 68.3333,  20.0000,  85.5000,  84.2000,  74.0000,  62.0000,  71.6667],\n","        [ 53.3333,  21.0000,  70.4000,  80.3000,  60.1500,  65.8400,  70.0000],\n","        [ 90.0000,  25.0000,  83.0000,  64.0000,  77.0000,  71.2500,  86.6667],\n","        [ 70.0000,  21.0000,  91.2000,  90.2000,  86.0000,  74.2250,  68.3333]]), Target: tensor([3, 2, 1, 0, 0, 1, 2, 1, 1, 1, 2])\n"]}]},{"cell_type":"code","source":["# prompt: how to access the dataloaders during the training phase for the model neural network\n","\n","# Access the dataloaders during training:\n","\n","# Iterate over the training dataloader\n","for epoch in range(100):\n","  for i, data in enumerate(train_dataloader):\n","    # Get inputs and labels\n","    inputs, labels = data\n","\n","    # Forward pass\n","    outputs = model(inputs)\n","\n","    # Calculate loss\n","    loss = loss_fxn(outputs, labels)\n","\n","    # Backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  # Evaluate the model on the test dataloader\n","  correct = 0\n","  total = 0\n","  with t.no_grad():\n","    for i, data in enumerate(test_dataloader):\n","      inputs, labels = data\n","      outputs = model(inputs)\n","      predictions = t.argmax(outputs, dim=1)\n","      correct += t.sum(predictions == labels)\n","      total += len(labels)\n","\n","  # Calculate accuracy\n","  accuracy = correct / total\n","  print(f\"Epoch {epoch+1}, Accuracy: {accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8I-cDuoNzZu3","executionInfo":{"status":"ok","timestamp":1710134236926,"user_tz":-330,"elapsed":2988,"user":{"displayName":"Friday V","userId":"05543200725873389140"}},"outputId":"a718bbe7-b3be-4f62-9caf-9b370a1272f1"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Accuracy: 0.19637462496757507\n","Epoch 2, Accuracy: 0.365558922290802\n","Epoch 3, Accuracy: 0.365558922290802\n","Epoch 4, Accuracy: 0.365558922290802\n","Epoch 5, Accuracy: 0.3262839913368225\n","Epoch 6, Accuracy: 0.365558922290802\n","Epoch 7, Accuracy: 0.365558922290802\n","Epoch 8, Accuracy: 0.365558922290802\n","Epoch 9, Accuracy: 0.37764349579811096\n","Epoch 10, Accuracy: 0.365558922290802\n","Epoch 11, Accuracy: 0.39274924993515015\n","Epoch 12, Accuracy: 0.3413897156715393\n","Epoch 13, Accuracy: 0.365558922290802\n","Epoch 14, Accuracy: 0.365558922290802\n","Epoch 15, Accuracy: 0.365558922290802\n","Epoch 16, Accuracy: 0.365558922290802\n","Epoch 17, Accuracy: 0.365558922290802\n","Epoch 18, Accuracy: 0.365558922290802\n","Epoch 19, Accuracy: 0.3262839913368225\n","Epoch 20, Accuracy: 0.395770400762558\n","Epoch 21, Accuracy: 0.365558922290802\n","Epoch 22, Accuracy: 0.3806646466255188\n","Epoch 23, Accuracy: 0.37764349579811096\n","Epoch 24, Accuracy: 0.39274924993515015\n","Epoch 25, Accuracy: 0.3987915515899658\n","Epoch 26, Accuracy: 0.3897280991077423\n","Epoch 27, Accuracy: 0.3987915515899658\n","Epoch 28, Accuracy: 0.39274924993515015\n","Epoch 29, Accuracy: 0.3897280991077423\n","Epoch 30, Accuracy: 0.3716011941432953\n","Epoch 31, Accuracy: 0.33836859464645386\n","Epoch 32, Accuracy: 0.3806646466255188\n","Epoch 33, Accuracy: 0.365558922290802\n","Epoch 34, Accuracy: 0.365558922290802\n","Epoch 35, Accuracy: 0.365558922290802\n","Epoch 36, Accuracy: 0.335347443819046\n","Epoch 37, Accuracy: 0.365558922290802\n","Epoch 38, Accuracy: 0.3716011941432953\n","Epoch 39, Accuracy: 0.365558922290802\n","Epoch 40, Accuracy: 0.365558922290802\n","Epoch 41, Accuracy: 0.365558922290802\n","Epoch 42, Accuracy: 0.3746223449707031\n","Epoch 43, Accuracy: 0.365558922290802\n","Epoch 44, Accuracy: 0.365558922290802\n","Epoch 45, Accuracy: 0.365558922290802\n","Epoch 46, Accuracy: 0.365558922290802\n","Epoch 47, Accuracy: 0.3806646466255188\n","Epoch 48, Accuracy: 0.3746223449707031\n","Epoch 49, Accuracy: 0.347432017326355\n","Epoch 50, Accuracy: 0.365558922290802\n","Epoch 51, Accuracy: 0.38368579745292664\n","Epoch 52, Accuracy: 0.365558922290802\n","Epoch 53, Accuracy: 0.3987915515899658\n","Epoch 54, Accuracy: 0.365558922290802\n","Epoch 55, Accuracy: 0.40181270241737366\n","Epoch 56, Accuracy: 0.3806646466255188\n","Epoch 57, Accuracy: 0.40181270241737366\n","Epoch 58, Accuracy: 0.40785497426986694\n","Epoch 59, Accuracy: 0.3504531681537628\n","Epoch 60, Accuracy: 0.40181270241737366\n","Epoch 61, Accuracy: 0.365558922290802\n","Epoch 62, Accuracy: 0.365558922290802\n","Epoch 63, Accuracy: 0.365558922290802\n","Epoch 64, Accuracy: 0.3746223449707031\n","Epoch 65, Accuracy: 0.39274924993515015\n","Epoch 66, Accuracy: 0.4108761250972748\n","Epoch 67, Accuracy: 0.40785497426986694\n","Epoch 68, Accuracy: 0.39274924993515015\n","Epoch 69, Accuracy: 0.4108761250972748\n","Epoch 70, Accuracy: 0.3897280991077423\n","Epoch 71, Accuracy: 0.40785497426986694\n","Epoch 72, Accuracy: 0.395770400762558\n","Epoch 73, Accuracy: 0.41691842675209045\n","Epoch 74, Accuracy: 0.39274924993515015\n","Epoch 75, Accuracy: 0.40785497426986694\n","Epoch 76, Accuracy: 0.40785497426986694\n","Epoch 77, Accuracy: 0.4108761250972748\n","Epoch 78, Accuracy: 0.40181270241737366\n","Epoch 79, Accuracy: 0.40785497426986694\n","Epoch 80, Accuracy: 0.39274924993515015\n","Epoch 81, Accuracy: 0.4048338234424591\n","Epoch 82, Accuracy: 0.4108761250972748\n","Epoch 83, Accuracy: 0.40785497426986694\n","Epoch 84, Accuracy: 0.39274924993515015\n","Epoch 85, Accuracy: 0.3987915515899658\n","Epoch 86, Accuracy: 0.395770400762558\n","Epoch 87, Accuracy: 0.4199395775794983\n","Epoch 88, Accuracy: 0.4108761250972748\n","Epoch 89, Accuracy: 0.395770400762558\n","Epoch 90, Accuracy: 0.39274924993515015\n","Epoch 91, Accuracy: 0.40785497426986694\n","Epoch 92, Accuracy: 0.39274924993515015\n","Epoch 93, Accuracy: 0.40785497426986694\n","Epoch 94, Accuracy: 0.4048338234424591\n","Epoch 95, Accuracy: 0.4108761250972748\n","Epoch 96, Accuracy: 0.4199395775794983\n","Epoch 97, Accuracy: 0.4108761250972748\n","Epoch 98, Accuracy: 0.4138972759246826\n","Epoch 99, Accuracy: 0.4108761250972748\n","Epoch 100, Accuracy: 0.41691842675209045\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nuaRDZqH0RX4","executionInfo":{"status":"ok","timestamp":1710134236926,"user_tz":-330,"elapsed":6,"user":{"displayName":"Friday V","userId":"05543200725873389140"}}},"execution_count":86,"outputs":[]}]}