{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3QRs-NOhzZLk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as model\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "YqPVmy5SzpdD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7xWVKyLztA4",
        "outputId": "47b7c399-2a4b-4ef8-c6d8-ed57a7cd228d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.conv1(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, (2, 2))\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, (2, 2))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = torch.nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "metadata": {
        "id": "4Md0zPnjz-u-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = LeNet()"
      ],
      "metadata": {
        "id": "TNTnUdVfzzQv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "6kX4ZkJHz10i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxbxGxnJ1roC",
        "outputId": "eebe1f48-3d66-418a-bd7a-88b552cf565f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.257\n",
            "[1,  4000] loss: 1.946\n",
            "[1,  6000] loss: 1.729\n",
            "[1,  8000] loss: 1.617\n",
            "[1, 10000] loss: 1.551\n",
            "[1, 12000] loss: 1.495\n",
            "[2,  2000] loss: 1.438\n",
            "[2,  4000] loss: 1.379\n",
            "[2,  6000] loss: 1.377\n",
            "[2,  8000] loss: 1.349\n",
            "[2, 10000] loss: 1.320\n",
            "[2, 12000] loss: 1.316\n",
            "[3,  2000] loss: 1.259\n",
            "[3,  4000] loss: 1.223\n",
            "[3,  6000] loss: 1.241\n",
            "[3,  8000] loss: 1.238\n",
            "[3, 10000] loss: 1.225\n",
            "[3, 12000] loss: 1.207\n",
            "[4,  2000] loss: 1.137\n",
            "[4,  4000] loss: 1.146\n",
            "[4,  6000] loss: 1.174\n",
            "[4,  8000] loss: 1.127\n",
            "[4, 10000] loss: 1.127\n",
            "[4, 12000] loss: 1.142\n",
            "[5,  2000] loss: 1.066\n",
            "[5,  4000] loss: 1.062\n",
            "[5,  6000] loss: 1.069\n",
            "[5,  8000] loss: 1.087\n",
            "[5, 10000] loss: 1.066\n",
            "[5, 12000] loss: 1.082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'lenet.pth')"
      ],
      "metadata": {
        "id": "q2S_lIlq1snW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVHyheuN264A",
        "outputId": "b8c9cc3c-63e0-470a-ad60-4080eb95ec66"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = LeNet()\n",
        "\n",
        "net.load_state_dict(torch.load('lenet.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR12c0Vr3EvD",
        "outputId": "e87dd004-3e7e-4b0e-945f-bda7652d9be5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_network(net, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "tAtBT-dR3NjX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_network(net, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caSzd3dV3PLn",
        "outputId": "7c46bac3-839c-4b88-f72a-a36da6d5a0ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 59 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open('/content/download.jpg')\n",
        "image = transform(image).unsqueeze(0)\n",
        "\n",
        "# Test the image\n",
        "output = net(image)\n",
        "_, predicted = torch.max(output, 1)\n",
        "print('Predicted class:', predicted.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEDDtw0j3Q3u",
        "outputId": "cc83f5ae-f5b0-4976-b193-2e5c795245ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2"
      ],
      "metadata": {
        "id": "WWp2hB0q54-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Df7iNvwt577q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "hORGAXsvPQHm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeWy-HyZQyZd",
        "outputId": "93e6fae2-ac18-46ae-97eb-4c4e5b00440e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = AlexNet()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "JH9Sf4S1P3pt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        # print('1')\n",
        "        optimizer.step()\n",
        "\n",
        "        # print('2')\n",
        "        running_loss += loss.item()\n",
        "        if i % 30 == 29:\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "        # print('3')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VypGFJW3P_Jh",
        "outputId": "e2ecc33e-6935-4118-f1cf-3c3802c8d65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    30] loss: 0.035\n",
            "[1,    60] loss: 0.034\n",
            "[1,    90] loss: 0.035\n",
            "[1,   120] loss: 0.035\n",
            "[1,   150] loss: 0.035\n",
            "[1,   180] loss: 0.035\n",
            "[1,   210] loss: 0.034\n",
            "[1,   240] loss: 0.035\n",
            "[1,   270] loss: 0.035\n",
            "[1,   300] loss: 0.034\n",
            "[1,   330] loss: 0.035\n",
            "[1,   360] loss: 0.035\n",
            "[1,   390] loss: 0.035\n",
            "[1,   420] loss: 0.034\n",
            "[1,   450] loss: 0.035\n",
            "[1,   480] loss: 0.035\n",
            "[1,   510] loss: 0.034\n",
            "[1,   540] loss: 0.035\n",
            "[1,   570] loss: 0.035\n",
            "[1,   600] loss: 0.035\n",
            "[1,   630] loss: 0.035\n",
            "[1,   660] loss: 0.035\n",
            "[1,   690] loss: 0.035\n",
            "[1,   720] loss: 0.035\n",
            "[1,   750] loss: 0.035\n",
            "[1,   780] loss: 0.034\n",
            "[1,   810] loss: 0.034\n",
            "[1,   840] loss: 0.035\n",
            "[1,   870] loss: 0.034\n",
            "[1,   900] loss: 0.034\n",
            "[1,   930] loss: 0.034\n",
            "[1,   960] loss: 0.034\n",
            "[1,   990] loss: 0.034\n",
            "[1,  1020] loss: 0.034\n",
            "[1,  1050] loss: 0.034\n",
            "[1,  1080] loss: 0.034\n",
            "[1,  1110] loss: 0.034\n",
            "[1,  1140] loss: 0.034\n",
            "[1,  1170] loss: 0.034\n",
            "[1,  1200] loss: 0.034\n",
            "[1,  1230] loss: 0.034\n",
            "[1,  1260] loss: 0.034\n",
            "[1,  1290] loss: 0.034\n",
            "[1,  1320] loss: 0.034\n",
            "[1,  1350] loss: 0.034\n",
            "[1,  1380] loss: 0.034\n",
            "[1,  1410] loss: 0.034\n",
            "[1,  1440] loss: 0.034\n",
            "[1,  1470] loss: 0.034\n",
            "[1,  1500] loss: 0.034\n",
            "[1,  1530] loss: 0.033\n",
            "[1,  1560] loss: 0.033\n",
            "[1,  1590] loss: 0.033\n",
            "[1,  1620] loss: 0.034\n",
            "[1,  1650] loss: 0.034\n",
            "[1,  1680] loss: 0.032\n",
            "[1,  1710] loss: 0.034\n",
            "[1,  1740] loss: 0.033\n",
            "[1,  1770] loss: 0.033\n",
            "[1,  1800] loss: 0.032\n",
            "[1,  1830] loss: 0.032\n",
            "[1,  1860] loss: 0.032\n",
            "[1,  1890] loss: 0.032\n",
            "[1,  1920] loss: 0.033\n",
            "[1,  1950] loss: 0.033\n",
            "[1,  1980] loss: 0.030\n",
            "[1,  2010] loss: 0.031\n",
            "[1,  2040] loss: 0.032\n",
            "[1,  2070] loss: 0.031\n",
            "[1,  2100] loss: 0.031\n",
            "[1,  2130] loss: 0.030\n",
            "[1,  2160] loss: 0.031\n",
            "[1,  2190] loss: 0.030\n",
            "[1,  2220] loss: 0.031\n",
            "[1,  2250] loss: 0.033\n",
            "[1,  2280] loss: 0.031\n",
            "[1,  2310] loss: 0.030\n",
            "[1,  2340] loss: 0.030\n",
            "[1,  2370] loss: 0.031\n",
            "[1,  2400] loss: 0.029\n",
            "[1,  2430] loss: 0.030\n",
            "[1,  2460] loss: 0.031\n",
            "[1,  2490] loss: 0.029\n",
            "[1,  2520] loss: 0.031\n",
            "[1,  2550] loss: 0.030\n",
            "[1,  2580] loss: 0.030\n",
            "[1,  2610] loss: 0.030\n",
            "[1,  2640] loss: 0.031\n",
            "[1,  2670] loss: 0.030\n",
            "[1,  2700] loss: 0.029\n",
            "[1,  2730] loss: 0.029\n",
            "[1,  2760] loss: 0.030\n",
            "[1,  2790] loss: 0.032\n",
            "[1,  2820] loss: 0.029\n",
            "[1,  2850] loss: 0.028\n",
            "[1,  2880] loss: 0.031\n",
            "[1,  2910] loss: 0.029\n",
            "[1,  2940] loss: 0.030\n",
            "[1,  2970] loss: 0.027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'alexnet.pth')"
      ],
      "metadata": {
        "id": "7gTRbjhsQDq3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}